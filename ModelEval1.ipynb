{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "file1=pd.read_csv(\"../FINAL DATA PREP/2015benign.csv\",index_col=0)\n",
    "file2=pd.read_csv(\"../FINAL DATA PREP/2015phishing.csv\",index_col=0)\n",
    "file3=pd.read_csv(\"../FINAL DATA PREP/2019benign.csv\",index_col=0)\n",
    "file4=pd.read_csv(\"../FINAL DATA PREP/2019phishing.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=file1.sample(frac=1)\n",
    "file3=file3.sample(frac=1)\n",
    "file4=file4.sort_values(\"month\")\n",
    "file2=file2.sort_values(\"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Label</th>\n",
       "      <th>protocol</th>\n",
       "      <th>nof_vowels</th>\n",
       "      <th>nof_consonants</th>\n",
       "      <th>nof_special_sym</th>\n",
       "      <th>nof_digits</th>\n",
       "      <th>nof_alpha</th>\n",
       "      <th>nof_alphanumeric</th>\n",
       "      <th>nof_ques</th>\n",
       "      <th>...</th>\n",
       "      <th>dig_in_hostname</th>\n",
       "      <th>alph_digit_ratio</th>\n",
       "      <th>host_dig_let_ratio</th>\n",
       "      <th>subdomain_len</th>\n",
       "      <th>dash_in_path</th>\n",
       "      <th>terms_in_url</th>\n",
       "      <th>longest_token</th>\n",
       "      <th>longest_token_hostname</th>\n",
       "      <th>length_of_domains</th>\n",
       "      <th>terms_in_subdomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895365</th>\n",
       "      <td>https://www.premierhousewares.co.uk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747837</th>\n",
       "      <td>https://www.portalinformatico.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482645</th>\n",
       "      <td>https://www.e-hutornaya.ru</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914084</th>\n",
       "      <td>https://www.bilgibirikimi.net</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86938</th>\n",
       "      <td>https://www.http://www.staples.com/Writing-Sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  Label  protocol  \\\n",
       "895365                https://www.premierhousewares.co.uk      0         1   \n",
       "747837                  https://www.portalinformatico.com      0         1   \n",
       "482645                         https://www.e-hutornaya.ru      0         1   \n",
       "914084                      https://www.bilgibirikimi.net      0         1   \n",
       "86938   https://www.http://www.staples.com/Writing-Sup...      0         1   \n",
       "\n",
       "        nof_vowels  nof_consonants  nof_special_sym  nof_digits  nof_alpha  \\\n",
       "895365          10              19                1           0         29   \n",
       "747837           8              20                1           0         28   \n",
       "482645           6              14                1           0         20   \n",
       "914084           7              17                1           0         24   \n",
       "86938           13              38                3           4         56   \n",
       "\n",
       "        nof_alphanumeric  nof_ques         ...          dig_in_hostname  \\\n",
       "895365                29         0         ...                        0   \n",
       "747837                28         0         ...                        0   \n",
       "482645                20         0         ...                        0   \n",
       "914084                24         0         ...                        0   \n",
       "86938                 60         0         ...                        0   \n",
       "\n",
       "        alph_digit_ratio  host_dig_let_ratio  subdomain_len  dash_in_path  \\\n",
       "895365              29.0                29.0              3             0   \n",
       "747837              28.0                28.0              3             0   \n",
       "482645              20.0                20.0              3             0   \n",
       "914084              24.0                24.0              3             0   \n",
       "86938               14.0                12.0              3             4   \n",
       "\n",
       "        terms_in_url  longest_token  longest_token_hostname  \\\n",
       "895365             5             17                      17   \n",
       "747837             4             17                      17   \n",
       "482645             5              9                       9   \n",
       "914084             4             13                      13   \n",
       "86938             10             11                       5   \n",
       "\n",
       "        length_of_domains  terms_in_subdomain  \n",
       "895365                 17                   1  \n",
       "747837                 17                   1  \n",
       "482645                 11                   1  \n",
       "914084                 13                   1  \n",
       "86938                   4                   1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>submission</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>week_number</th>\n",
       "      <th>Label</th>\n",
       "      <th>protocol</th>\n",
       "      <th>nof_vowels</th>\n",
       "      <th>nof_consonants</th>\n",
       "      <th>nof_special_sym</th>\n",
       "      <th>nof_digits</th>\n",
       "      <th>...</th>\n",
       "      <th>alph_digit_ratio</th>\n",
       "      <th>host_dig_let_ratio</th>\n",
       "      <th>subdomain_len</th>\n",
       "      <th>dash_in_path</th>\n",
       "      <th>terms_in_url</th>\n",
       "      <th>longest_token</th>\n",
       "      <th>longest_token_hostname</th>\n",
       "      <th>length_of_domains</th>\n",
       "      <th>terms_in_subdomain</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16032</th>\n",
       "      <td>http://konto-einloggen.93498.login.gj2j.com/de...</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15776</th>\n",
       "      <td>http://hirobadqxjp.sesp.cu.cc/</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>http://hirobadqxjp.sesq.cu.cc/account/app/svc/...</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>http://hirobadqxjp.sesq.cu.cc/</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15780</th>\n",
       "      <td>http://hirobadqxjp.sesr.cu.cc/</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  submission  \\\n",
       "16032  http://konto-einloggen.93498.login.gj2j.com/de...  2014-01-01   \n",
       "15776                     http://hirobadqxjp.sesp.cu.cc/  2014-01-21   \n",
       "15777  http://hirobadqxjp.sesq.cu.cc/account/app/svc/...  2014-01-21   \n",
       "15778                     http://hirobadqxjp.sesq.cu.cc/  2014-01-21   \n",
       "15780                     http://hirobadqxjp.sesr.cu.cc/  2014-01-21   \n",
       "\n",
       "        Timestamp  week_number  Label  protocol  nof_vowels  nof_consonants  \\\n",
       "16032  2014-01-01            1      1         0          12              27   \n",
       "15776  2014-01-21            4      1         0           5              18   \n",
       "15777  2014-01-21            4      1         0          11              34   \n",
       "15778  2014-01-21            4      1         0           5              18   \n",
       "15780  2014-01-21            4      1         0           5              18   \n",
       "\n",
       "       nof_special_sym  nof_digits  ...    alph_digit_ratio  \\\n",
       "16032                1           6  ...                 6.5   \n",
       "15776                1           0  ...                23.0   \n",
       "15777                1           0  ...                45.0   \n",
       "15778                1           0  ...                23.0   \n",
       "15780                1           0  ...                23.0   \n",
       "\n",
       "       host_dig_let_ratio  subdomain_len  dash_in_path  terms_in_url  \\\n",
       "16032            4.833333             27             2            10   \n",
       "15776           23.000000             16             1             5   \n",
       "15777           23.000000             16             4            10   \n",
       "15778           23.000000             16             1             5   \n",
       "15780           23.000000             16             1             5   \n",
       "\n",
       "       longest_token  longest_token_hostname  length_of_domains  \\\n",
       "16032              9                       9                  4   \n",
       "15776             11                      11                  2   \n",
       "15777             11                      11                  2   \n",
       "15778             11                      11                  2   \n",
       "15780             11                      11                  2   \n",
       "\n",
       "       terms_in_subdomain  month  \n",
       "16032                   4      1  \n",
       "15776                   2      1  \n",
       "15777                   2      1  \n",
       "15778                   2      1  \n",
       "15780                   2      1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2=file2.drop([\"submission_time\"],axis=1)\n",
    "file2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign2015=file1\n",
    "phish2015=file2.drop([\"submission\",\"Timestamp\",\"week_number\",\"month\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign2019=file3\n",
    "phish2019=file4.drop([\"submission\",\"Timestamp\",\"year\",\"week_number\",\"month\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089803 1091254 25228 44416\n"
     ]
    }
   ],
   "source": [
    "print(len(benign2015),len(benign2019),len(phish2015),len(phish2019))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now on a monthly basis for latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1089800\n",
       "1      10898\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y15_100.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    4717\n",
       "16    4539\n",
       "6     4498\n",
       "15    3919\n",
       "11    3051\n",
       "7     3048\n",
       "5     2719\n",
       "4     2619\n",
       "3     2450\n",
       "10    2173\n",
       "2     2082\n",
       "14    1996\n",
       "12    1792\n",
       "9     1408\n",
       "1     1354\n",
       "8     1027\n",
       "13    1024\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file4.month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     10232\n",
       "7      4185\n",
       "8      2947\n",
       "4      2439\n",
       "5      1988\n",
       "3      1214\n",
       "2       693\n",
       "12      464\n",
       "1       421\n",
       "11      360\n",
       "10      222\n",
       "9        63\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2.month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary of urls based on months for the year 2015\n",
    "dict_of_months_2015 = {k: v for k, v in file2.groupby('month')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary of urls based on months for the year 2019\n",
    "dict_of_months_2019 = {k: v for k, v in file4.groupby('month')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[421, 693, 1214, 2439, 1988, 10232, 4185, 2947, 63, 222, 360, 464]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL lengths for the year 2015 are\n",
    "L2015 = []\n",
    "for key,values in dict_of_months_2015.items():\n",
    "    L2015.append(len(values))\n",
    "L2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL lengths for the year 2019 are\n",
    "L2019 = []\n",
    "for key,values in dict_of_months_2019.items():\n",
    "    L2019.append(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlist= [\"jan1\",\"feb1\",\"mar1\",\"apr1\",\"may1\",\"jun1\",\"jul1\",\"aug1\",\"sep1\",\"oct1\",\"nov1\",\"dec1\",\"jan2\",\"feb2\",\"mar2\",\"apr2\",\"may2\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1354,\n",
       " 3436,\n",
       " 5886,\n",
       " 8505,\n",
       " 11224,\n",
       " 15722,\n",
       " 18770,\n",
       " 19797,\n",
       " 21205,\n",
       " 23378,\n",
       " 26429,\n",
       " 28221,\n",
       " 29245,\n",
       " 31241,\n",
       " 35160,\n",
       " 39699,\n",
       " 44416]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "k = []\n",
    "for i in L2019:\n",
    "    sum = sum+i\n",
    "    k.append(sum)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "test_dict = {}\n",
    "for j, i in enumerate(k):\n",
    "    if j == 0: \n",
    "        variable = file4[0:i].append(file3[0:i])\n",
    "        test_dict[monthlist[j]]=variable\n",
    "    else:\n",
    "        variable = file4[k[j-1]:k[j]].append(file3[k[j-1]:k[j]])\n",
    "        test_dict[monthlist[j]]= variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of training set\n",
    "#### 1:1      =     25228 : 25228              2015\n",
    "#### 1:1      =     44416 : 44416              2019\n",
    "#### 1:100  = 1089800 : 10898              2015\n",
    "#### 1:100  = 1091200 : 10912              2019\n",
    "#### Train test split 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25228"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phish2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2015on1=benign2015[:25228].append(phish2015)\n",
    "\n",
    "dataset2015on100=(benign2015[:1089800]).append(phish2015[:10898])\n",
    "\n",
    "dataset2019on1=benign2019[:44416].append(phish2019)\n",
    "\n",
    "dataset2019on100=benign2019[:1091200].append(phish2019[:10912])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset2015on1=dataset2015on1.sample(frac=1)\n",
    "dataset2015on100=dataset2015on100.sample(frac=1)\n",
    "dataset2019on1=dataset2019on1.sample(frac=1)\n",
    "dataset2019on100=dataset2019on100.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def logistic_predictions(X_test,y_test):\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test,predictions))\n",
    "    from sklearn.metrics import confusion_matrix,classification_report\n",
    "    print (\"\\n\",classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9969282600079271\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5002\n",
      "           1       1.00      1.00      1.00      5090\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10092\n",
      "   macro avg       1.00      1.00      1.00     10092\n",
      "weighted avg       1.00      1.00      1.00     10092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Prediction for 1 on 1 2015\n",
    "X15_1 = dataset2015on1.drop([\"url\",\"Label\"],axis=1)\n",
    "y15_1 = dataset2015on1.Label\n",
    "X15_1_train, X15_1_test, y15_1_train, y15_1_test = train_test_split( X15_1, y15_1, test_size = 0.2, random_state = 100)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X15_1_train,y15_1_train)\n",
    "logistic_predictions(X15_1_test,y15_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975779005685483\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1089800\n",
      "           1       0.81      1.00      0.89     10898\n",
      "\n",
      "   micro avg       1.00      1.00      1.00   1100698\n",
      "   macro avg       0.90      1.00      0.94   1100698\n",
      "weighted avg       1.00      1.00      1.00   1100698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction for 1 on 100 2015\n",
    "X15_100 = dataset2015on100.drop([\"url\",\"Label\"],axis=1)\n",
    "y15_100 = dataset2015on100.Label\n",
    "logistic_predictions(X15_100,y15_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9238562680115274\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     44416\n",
      "           1       0.92      0.93      0.92     44416\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     88832\n",
      "   macro avg       0.92      0.92      0.92     88832\n",
      "weighted avg       0.92      0.92      0.92     88832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction for 1 on 1 2019\n",
    "X19_1 = dataset2019on1.drop([\"url\",\"Label\"],axis=1)\n",
    "y19_1 = dataset2019on1.Label\n",
    "logistic_predictions(X19_1,y19_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9197449986934177\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96   1091200\n",
      "           1       0.11      0.96      0.19     10912\n",
      "\n",
      "   micro avg       0.92      0.92      0.92   1102112\n",
      "   macro avg       0.55      0.94      0.57   1102112\n",
      "weighted avg       0.99      0.92      0.95   1102112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction for 1 on 100 2019\n",
    "X19_100 = dataset2019on100.drop([\"url\",\"Label\"],axis=1)\n",
    "y19_100 = dataset2019on100.Label\n",
    "logistic_predictions(X19_100,y19_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'Timestamp', 'alph_digit_ratio', 'dash_in_path',\n",
       "       'dig_in_hostname', 'dots_freeurl', 'host_dig_let_ratio', 'len_url',\n",
       "       'length_fqdn', 'length_freeurl', 'length_of_domains', 'longest_token',\n",
       "       'longest_token_hostname', 'month', 'nof_alpha', 'nof_alphanumeric',\n",
       "       'nof_at', 'nof_consonants', 'nof_dash', 'nof_digits', 'nof_dir',\n",
       "       'nof_dollar', 'nof_dots', 'nof_eq', 'nof_http', 'nof_percent',\n",
       "       'nof_ques', 'nof_special_sym', 'nof_vowels', 'nof_www', 'protocol',\n",
       "       'subdomain_len', 'submission', 'terms_in_subdomain', 'terms_in_url',\n",
       "       'url', 'vowel_consonant_ratio', 'week_number', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[\"jan2\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for jan1 \n",
      "\n",
      "0.5003692762186115\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1354\n",
      "           1       1.00      0.00      0.00      1354\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      2708\n",
      "   macro avg       0.75      0.50      0.33      2708\n",
      "weighted avg       0.75      0.50      0.33      2708\n",
      "\n",
      "None\n",
      "Prediction for feb1 \n",
      "\n",
      "0.5002401536983669\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      2082\n",
      "           1       1.00      0.00      0.00      2082\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      4164\n",
      "   macro avg       0.75      0.50      0.33      4164\n",
      "weighted avg       0.75      0.50      0.33      4164\n",
      "\n",
      "None\n",
      "Prediction for mar1 \n",
      "\n",
      "0.5\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      2450\n",
      "           1       0.50      0.00      0.00      2450\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      4900\n",
      "   macro avg       0.50      0.50      0.33      4900\n",
      "weighted avg       0.50      0.50      0.33      4900\n",
      "\n",
      "None\n",
      "Prediction for apr1 \n",
      "\n",
      "0.5001909125620466\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      2619\n",
      "           1       1.00      0.00      0.00      2619\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      5238\n",
      "   macro avg       0.75      0.50      0.33      5238\n",
      "weighted avg       0.75      0.50      0.33      5238\n",
      "\n",
      "None\n",
      "Prediction for may1 \n",
      "\n",
      "0.501655020228025\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      2719\n",
      "           1       1.00      0.00      0.01      2719\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      5438\n",
      "   macro avg       0.75      0.50      0.34      5438\n",
      "weighted avg       0.75      0.50      0.34      5438\n",
      "\n",
      "None\n",
      "Prediction for jun1 \n",
      "\n",
      "0.5001111605157847\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      4498\n",
      "           1       1.00      0.00      0.00      4498\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      8996\n",
      "   macro avg       0.75      0.50      0.33      8996\n",
      "weighted avg       0.75      0.50      0.33      8996\n",
      "\n",
      "None\n",
      "Prediction for jul1 \n",
      "\n",
      "0.5003280839895013\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3048\n",
      "           1       1.00      0.00      0.00      3048\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      6096\n",
      "   macro avg       0.75      0.50      0.33      6096\n",
      "weighted avg       0.75      0.50      0.33      6096\n",
      "\n",
      "None\n",
      "Prediction for aug1 \n",
      "\n",
      "0.49951314508276534\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1027\n",
      "           1       0.00      0.00      0.00      1027\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      2054\n",
      "   macro avg       0.25      0.50      0.33      2054\n",
      "weighted avg       0.25      0.50      0.33      2054\n",
      "\n",
      "None\n",
      "Prediction for sep1 \n",
      "\n",
      "0.5\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1408\n",
      "           1       0.00      0.00      0.00      1408\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      2816\n",
      "   macro avg       0.25      0.50      0.33      2816\n",
      "weighted avg       0.25      0.50      0.33      2816\n",
      "\n",
      "None\n",
      "Prediction for oct1 \n",
      "\n",
      "0.5\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      2173\n",
      "           1       0.00      0.00      0.00      2173\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      4346\n",
      "   macro avg       0.25      0.50      0.33      4346\n",
      "weighted avg       0.25      0.50      0.33      4346\n",
      "\n",
      "None\n",
      "Prediction for nov1 \n",
      "\n",
      "0.5\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3051\n",
      "           1       0.00      0.00      0.00      3051\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      6102\n",
      "   macro avg       0.25      0.50      0.33      6102\n",
      "weighted avg       0.25      0.50      0.33      6102\n",
      "\n",
      "None\n",
      "Prediction for dec1 \n",
      "\n",
      "0.5002790178571429\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1792\n",
      "           1       1.00      0.00      0.00      1792\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      3584\n",
      "   macro avg       0.75      0.50      0.33      3584\n",
      "weighted avg       0.75      0.50      0.33      3584\n",
      "\n",
      "None\n",
      "Prediction for jan2 \n",
      "\n",
      "0.5\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1024\n",
      "           1       0.00      0.00      0.00      1024\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      2048\n",
      "   macro avg       0.25      0.50      0.33      2048\n",
      "weighted avg       0.25      0.50      0.33      2048\n",
      "\n",
      "None\n",
      "Prediction for feb2 \n",
      "\n",
      "0.5\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1996\n",
      "           1       0.00      0.00      0.00      1996\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      3992\n",
      "   macro avg       0.25      0.50      0.33      3992\n",
      "weighted avg       0.25      0.50      0.33      3992\n",
      "\n",
      "None\n",
      "Prediction for mar2 \n",
      "\n",
      "0.5001275835672365\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3919\n",
      "           1       1.00      0.00      0.00      3919\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      7838\n",
      "   macro avg       0.75      0.50      0.33      7838\n",
      "weighted avg       0.75      0.50      0.33      7838\n",
      "\n",
      "None\n",
      "Prediction for apr2 \n",
      "\n",
      "0.5001101564221194\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      4539\n",
      "           1       1.00      0.00      0.00      4539\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      9078\n",
      "   macro avg       0.75      0.50      0.33      9078\n",
      "weighted avg       0.75      0.50      0.33      9078\n",
      "\n",
      "None\n",
      "Prediction for may2 \n",
      "\n",
      "0.5008479966080136\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      4717\n",
      "           1       1.00      0.00      0.00      4717\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      9434\n",
      "   macro avg       0.75      0.50      0.34      9434\n",
      "weighted avg       0.75      0.50      0.34      9434\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\arabraha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in test_dict:\n",
    "    X = test_dict[i].drop([\"url\",\"Label\",\"Timestamp\",\"week_number\",\"year\",\"submission\",\"month\"],axis=1)\n",
    "    y = test_dict[i].Label\n",
    "    print(\"Prediction for\",i,\"\\n\")\n",
    "    print(logistic_predictions(X,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
